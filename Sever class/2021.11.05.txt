메모리
 1. 예외처리
  1) 메모리 할당 실패 시 프로그램 다운시키는게 정상적 동작. (때문에 예외처리를 하지않아도 됨) 다운된 이후 메모리 덤프로 디버깅
  2) 모종의 이유로 유저를 찾는 과정이 있는데(유저는 분명히 어떠한 리스트에 존재한다), 찾지 못하였다면 결함으로 인식하여 예외처리를 하여 다운시켜야함. (더이상의 코드를 진행시키면 안됨.)
   => 예외처리 방법: 포인터 변수에 nullptr을 대입하고, nullptr에 0을 저장하여 프로그램을 다운시킨다.
   
 2. 캐시 메모리
  1) Core마다 각각 L1, L2가 구성되고 L3(스마트 캐시)는 공유한다.
  2) 캐시 히트: Core가 캐시에게 데이터를 요청하였을때 데이터가 존재하는 상황 <-> 캐시 미스: 캐시 히트의 반대
   => Core는 Cache L1->L2->L3->RAM 순으로 데이터를 찾는다. RAM에도 없다면 MMU가 Page Fault를 발생시켜 해당 메모리를 Page In(Blocking 발생)
  3) 캐시 메모리의 특성
   (1) 캐시 메모리는 메인 메모리에서 캐시 라인 단위(현재는 64Byte 단위)로 주소를 마스킹하여 데이터를 캐시 라인으로 긁어온다.
   (2) 캐시 메모리는 코드 캐시와 데이터 캐시로 1/2씩 공간이 나누어진다. 코드영역 데이터는 코드 캐시로 데이터(Heap, 데이터, Stack)는 데이터 캐시로 이동한다.
   (3) 각 Core들은 캐시 라인의 변화를 다른 Core들에게 알려 같은 데이터를 가진 캐시 라인들의 데이터를 무효화(삭제)시킨다.
    => 무효화가 일어난 캐시 라인은 다음에 해당 데이터를 사용 시 같은 레벨의 캐시 라인에서 데이터를 끌어온다.
    => 캐시 라인들은 캐시 미스가 날 경우, 첫 번째로 같은 레벨들끼리 통신을 하여 캐시 미스가 일어날 경우 데이터를 긁어온다. 그래도 캐시 미스가 나면 다음 레벨을 검색하여 긁어온다.
  4) alignas 키워드 활용 방법
   (1) 캐시 히트를 높이는 방법 1 (쓰기나 읽기 어느 하나의 단일 동작 시)
    (1-1) 시간적 근접성: 연속적인 동작에 같은 변수를 사용
    (1-2) 지역적 근접성: 연속된 메모리를 사용 => 3)의 특성 때문
	(1-3) 위 두 가지 근접성은 캐시 라인 크기에 맞게 alignment 경계를 세워 캐시 히트율을 높이기 위함이다.
	(1-4) 구현 방법: 예를 들어 구조체 단위의 데이터라면, struct alignas(캐시 라인 크기)로 정의하여 사용
   *) 지역 변수와 전역 변수의 접근하는 속도에는 차이가 없다. 단, 지역과 전역 변수를 섞어서 사용 시 캐시 미스가 일어나 성능 저하를 가져온다.
   (2) 캐시 히트를 높이는 방법 2 (읽기와 쓰기를 동시에 동작하는 경우)
	(2-1) 목적: 읽기 변수와 쓰기 변수가 있는 경우 의도적으로 두 변수를 다른 캐시 라인에 적재하여, 캐시 라인 무효화를 최대한 막는다. ( 7)의 특성)
    (2-2) 구현 방법: 읽기 변수와 쓰기 변수의 주소를 alignas(캐시 라인 크기)만큼 벌려놓아 사용한다.
  5) 캐시 메모리 쓰기 정책
   (1)write back(데이터 캐시): 변경된 데이터를 캐시에만 적용
   => 메모리 적용시기는 해당 캐시 데이터가 캐시 라인에서 지울때이다.
   (2)write through(코드 캐시): 변경된 데이터를 메모리까지 적용

*malloc 할당 실패는 가상메모리 상에서의 공간이 부족한 경우이다. (OS입장에서 물리 메모리는 무한하다고 보기 때문이다.)
*** 메모리 풀 구현해보기
****빌드 팜
timeGetTime