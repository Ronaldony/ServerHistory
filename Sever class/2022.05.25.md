# 2022/05/25 수업내용
# IO
## 비동기 IO
### 파일 비동기 IO의 문제점
1. 한 파일을 대상으로 비동기 IO를 수행하면 파일 위치 정보가 항상 0이다. 그래서 그냥 비동기 Output을 여러번 수행하면 데이터가 덮어 써지는 경우가 있다. 이것은 잘못된 사용 방법이다. 따라서 OVERLAPPED 구조체의 offset을 변경하여 파일 위치 정보를 전달해야 한다.
2. 수준 높은 OS 관련 서적을 보다보면 메모리와 관련해서 캐시 캐시라는 단어가 언급된다. 메모리 속성의 캐시라던가 메모리 영역이 캐시라는 메모리와 관련하여 언급이 된다.
    1) 여기서 말하는 캐시는 우리가 아는 CPU의 캐시 메모리가 아니다. 파일 IO에 대한 캐시이다. 우리가 파일 IO에 대한 작업을 요청하면 OS 차원에서 해당 파일에 대한 캐시를 진행한다.
        * 이 캐시는 C 런타임의 버퍼링과는 OS에서 파일 시스템적으로 버퍼링하는 작업인 것이다. C 런타임 버퍼링은 언어 차원에서의 읽기 쓰기 버퍼를 만들어놓은 것이고 OS 메모리 캐시는 윈도우 IO 시스템 내부에 있는 캐시 구조이다.
    2) 이 캐시에 파일이 캐시되어 있다면 그 순간은 Overlapped IO가 작동되지 않는다. 메모리에 쓰거나 읽어 올 수 있기 때문에 실제 파일에 대한 Disk IO를 작업을 요청할 필요가 없기 때문이다. 그래서 캐시 됐다라면 커널이 백그라운드에서 알아서 할 동작이 된다.
        * 캐시 되어있는 데이터는 Disk에 있는 데이터보다 더 최신 데이터이다.
    3) 결론적으로 캐시가 되지 않은 파일에 대해서만 Overlapped IO가 이루어진다.

### Overlapped
1. IO가 동시에 이루어질 수 있는 것이냐?
   1) 동시에 이루어질수는 없다. 위에서 언급한 파일 IO의 경우 offset 0 자리에서 차례대로 수행되면서 계속해서 덮어쓰는 형태인 것이다.
2. Overlapped 함수들의 반환
   1) Overlapped IO가 작동됐다면 IO_PENDDING 이 반환된다. => IO_PENDDING 이 반환되지 않았다면 동기 IO로 동작한 것이다. 이때 수신 혹은 송신한 데이터 크기 cbTransferred는 유효한 값일 것이다. 함수 반환 시점에서 동작이 완료되었기 때문에

### 소켓 비동기 IO
1. 소켓 Overlapped IO의 작동 시점
   1) Overlapped IO 라고 하는 것은 디바이스 자체가 하는 것이다. IO를 중첩(Overlapped)으로 겁니다 라는 행위가 가능해지려면 해당 디바이스에 걸때만 가능하다. 여기서 건다는 것은 디바이스에 실제 IO 해야하는 버퍼의 주소를 전달하여 디바이스가 해당 버퍼에 직접 접근한다는 의미이다.
   2) 네트워크 IO든 파일 IO든 중간 버퍼에 넣고 빠지는 형태라면 Overlapped IO가 작동되는 것이 아니다. 이러한 상황은 동기 IO 작동 방식이다. 이 말은 우리가 OVERLAPPED 구조체를 생성하여 OVERLAPPED 지원 함수를 호출한다해도 무조건적으로 Overlapped IO가 작동한다는 얘기가 아닌 것이다.
      * 네트워크 IO를 예로 송신 소켓 버퍼에 Copy를 할 때 우리의 스레드가 커널 모드로 전환하여 Copy를 하는 것은 맞지만, 이게 Overlapped IO의 동작은 아니다. 수신 동작도 이와 마찬가지이다.
   3) 쉽게 말해서 Overlapped IO가 작동되려면 사용자가 요청한 작업을 지금 당장 완료할 수 없는 상황이 되어야 한다.
2. WSASend와 WSARecv와 Overlapped IO
   1) WSARecv: 이 함수를 호출하는 시점에 소켓 수신 버퍼가 비어있다면? => Block이 걸릴 조건이 된다.(물론 비동기이므로 Block은 안 걸림) 이때 Overlapped IO가 작동한다.
   2) WSASend: 이 함수를 호출하는 시점에 소켓 송신 버퍼가 꽉 차 있다면? => Block이 걸릴 조건이 된다. 이때 Overlapped IO가 작동한다.
3. WSAOVERLAPPED 구조체에서 offset은 사용되지 않는다. 파일 IO와는 달리 애초에 소켓 버퍼는 offset에 의존하지 않는다.

### 소켓 Overlapped IO에 대한 개발자들의 고민과 결론
1. 고민: 2000년대 초반 개발자들의 Overlapped IO 처리 순서와 반환 값에 대한 고민
    1) 여기서 가정하는 시나리오는 다음과 같다. 하나의 소켓을 대상으로 WSASend를 3번 호출하는데 매번 다른 버퍼를 대상으로 호출한다. 차례대로 100->200->150 크기로 전송 요청하였다.
    2) 옛날 개발자들의 고민: 위와 같은 경우에 실제 어떻게 동작할 것인가?를 고민했다. 여기서 어떻게란 송신 혹은 수신된 바이트에 대한 반환 값 그리고 순서이다.
        * 고민1: 파일 IO와 엮은 상황이다. 하나의 파일 IO에 여러번 걸쳐 썼더니 덮어써지더라 => 그래서 소켓 또한 순서대로가 아닌 동시에 IO가 이루어져 데이터가 덮어씌어지는 것이 아닌가?
        * 고민2: 마이크로소프트에서 말하는 Overlapped IO의 장점은 비동기적으로 백그라운드에서 작업을 한다는 것이다. 때문에 필요할 때마다 WSASend를 요청해도 문제가 되지 않겠네? => 그런데 차례대로 요청한 크기에 대한 IO 결과 값은 어떻게 될 것인가? 예를 들어 첫 번째 100 요청의 결과가 70이고 두 번째 200 요청의 결과가 150인 상황이 나왔을 때 이 결과는 무엇을 의미하냐 이다.
    3) 위와 같은 고민들로 인해 옛날 개발자들은 하나의 소켓을 대상으로 이전 WSASend 또는 WSARecv 완료되어야만 다음 WSASend 또는 WSARecv를 호출하자 라는 결론을 내렸다.
        * 어떤 순서, 어떤 결과가 나올 지 예측할 수 없으니
2. 결론: 현재 개발자들의 Overlapped IO 처리 순서와 반환 값에 대한 결론
    1) 여기서 가정하는 시나리오는 위에서 언급한 시나리오와 동일하다.
    2) 결론1: 요청에 대한 처리 완료 순서가 지켜진다. 중첩으로 IO 작업을 걸어도 앞에 요청된 작업이 완료되어야만 뒤에 요청된 작업이 수행된다.
        * 결론적으로 순서와 크기에 대한 반환 값은 모두 요청과 정확히 일치한다. 아래 Overlapped의 동작 조건을 살펴보자. 소켓 버퍼에 공간이 없어 디바이스에 IO를 걸고 빠지는 상태가 된다.
    3) 결론2: 요청에 대한 송수신 크기의 반환 값은 요청 크기와 정확히 동일하다. 중첩으로 IO 작업을 걸었다해도 작업당에 대한 결과값을 보장해준다는 이야기이다.
        * 이 결론에 대한 유추는 Overlapped IO 조건을 생각하면 답이 나온다. Overlapped는 Block이 걸려야하는 상황에서 걸리지 않고 디바이스에 버퍼를 걸고(작업을 맡기고) 함수가 반환되는 것이다.
        * Block 소켓 Send를 예로 들어보자. 요청 크기보다 송신 소켓 버퍼의 여유가 없을 때 Block이 걸린다. 이때 Send가 반환할 수 있는 값은 무엇이 있는가? 요청한 크기 혹은 SOCKET_ERROR이다.(연결이 끊긴 상황은 제외) Overlapped IO 상황은 이 상황과 정확히 일치한다. Block만! 안 걸릴 뿐이다. 따라서 절대 요청 크기보다 작은 값을 반환해주는 상황은 벌어지지 않을 것이다.
        * 송신을 예로 들면 100을 요청했을때 소켓 송신 버퍼에 70만큼 자리가 있다면 70만 동기 IO하고 30은 Overlapped IO로 전환하는 상황이 된다.
        * 옛날 개발자들은 이러한 동작을 정확히 파악하지 못하여 GetOverlappedResult 호출 후에 송신 크기보다 작은 크기 반환 값에 대비한 코드를 작성하였다. 이러한 상황은 절대 일어날 수 없는데도 말이다.
    4) 결론2와 관련해 요청 크기보다 작은 경우가 나올 수 있다. 그 경우는 하다가 실패, 하다가 연결 끊기는 것이다. 그래서 마지막에 한 번 이를 검사하는 코드를 넣을 것이다. 그리고 이것을 버릴 것이다.
3. 2.의 결론에도 불구하고 우리는 여전히 WSASend와 WSARecv 중첩으로 하지 않는다. 그 이유는 다음과 같다.
    1) 이유1: Overlapped IO의 성능이 좋지 않기 때문이다. 
    2) 이유2: OVERLAPPED 구조체를 어떻게 관리해야할지도 난해하다.
        * 난해1: 완료 통지가 오기 전까지 보존이 되어야 한다. => 그래서 세션 별로 OVERLAPPED 구조체를 동적 할당하여 관리하자라는 아이디어가 나온다. 그러나 이 방법은 동적 할당에 대한 오버헤드가 생긴다.
    3) 이유3: 실제로 Overlapped IO가 작동되기 위해서 윈도우 시스템은 무엇을 하는가이다.
        * 하는 일1: Page out이 되지 않기 위해 요청된 유저 메모리 버퍼의 Page가 Page Lock이 걸리게 된다. (여기서 말하는 Page Lock은 Page out 되지 않게 거는 lock이다.) Overlapped IO가 작동되는 순간 recv 혹은 send로 요청된 유저 메모리 버퍼는 디바이스로부터 직접 접근된다.(이 동작을 Zero Copy라고 한다) 이때 해당 버퍼는 없어져서도 안되고 Page out 상태가 되어서도 안 된다.
        * 하는 일2: 해당 IO에 대한 작업 요청 즉 I/O request packet가 Non-Page Pool로 할당이 되어야 한다. 동기 IO에서는 고려되지 않았지만 Overlapped IO라면 많이 쌓일 것이다. recv가 대표적이다.
4. 3.의 이유3과 관련하여 논의할만한 상황
    1) Page Lock: 물리 메모리의 몇%밖에 할 수 없는 상황
        * 예방할 수 있는 방법: Page Lock을 최소화 하는 것. 메모리들의 주소를 4K로 정렬하여 최소화시킬 수 있다.
    2) 결론적으로 Page Lock -> I/O request packet 등록 후에야 IO pending이 반환된다. 과연 이 작업들이 실제 IO 작업을 기다리는 것보다 과연 짧은가를 따져야한다.
        * 이러한 문제사항은 스스로 판단해야 한다. 이러한 상황에서도 Overlapped IO가 어떤 경우에 성능이 좋아지는지에 대한 판단과 테스트를 통해 스스로 판단이 필요하다.
    
### Zero Copy, Page Lock, IO Request Packet
1. Zero copy: 중간 버퍼의 Copy 행위를 없애서 송수신 효과를 높여보자. 이것은 우리 입장에서 Overlapped IO 이다.
    1) Zero copy의 대상 버퍼는 Page out 되지 않아야 한다. 따라서 Page out이 되지 않기 위한 Page Lock이 걸린다.
2. Page Lock
    1) Page Lock은 실제 물리 메모리의 몇 %인가로 한정되어 있다. 커널마다 다르다.
4. I/O request packet: IO 요청 정보들(네트워크, 파일 IO 등)
    1) Non-Paged Pool에 할당된다.
    2) I/O request packet에 대한 작업을 관리하는 주체는 스레드이다.
        * 스레드가 파괴되면 I/O도 모두 중단하게 되어있다.
        * 동기 IO라면 하나의 스레드가 하나의 작업을 요청하고 하나의 작업이 끝나야 다음 작업이 수행된다. 애초에 I/O request packet가 많이 쌓일 수가 없다.
        * 그러나 비동기 IO라면 다수의 Request IO paket이 생겨 관리가 필요하다.

### 소켓 에러
1. WSAENOBUFS
    1) 대부분이 리소스 부족이 일어날 때 나오는 에러이다. Page Lock에 실패하거나 Non-Page Pool에 대한 확보에 실패했을 때도 이 에러가 발생한다.
    2) 이 에러가 나오면 서버를 종료시키는 것보단 해당 유저의 연결을 끊는 것이 낫다.
    3) 대처 방안
        * 첫 번째: Non-Paged pool 크기를 확인한 후 실제 Scale up
        * 두 번째: 
        * 최후의 방법: 동접자 줄이기
2. 에러 값을 찍는 것은 일반적인 에러와 일반적이지 않은 에러를 구분하는 것에 목적이 있다.
    1) 따라서 일반적인 에러들을 

### IOCP
1. 작업 완료의 기준: 연결이 끊겼거나 진짜 작업이 완료되었거나 이다.
2. 다른 스레드가 아닌 내 스레드가 APC 큐에서 디큐잉해서 완료 루틴을 호출한다.
    1) alertable wait: APC 큐에 있는 함수 호출을 기다리는 상태 
3. APC 큐의 단점
    1) 스레드가 자기만의 APC큐를 가지기 때문에 IO 완료 통지가 해당 스레드에만 전달된다. 다른 스레드에 분산이 안 된다.
4. 완료 루틴을 호출하는 도중에 APC 큐에 쌓일 수 가 있다. 이때 Alertable wait 상태라면 APC 큐에 있는 함수를 모두 호출하고 리턴이 된다.
5. 우리는 APC 큐 방식을 사용하지 않을거지만 활용할 것이다.
    1) 우리는 완료 통지 목적으로 APC를 사용하는게 아니라 의도적으로 UserAPCQueue 함수를 호출하여 사용할 것이다.
