# 2022/05/09 수업내용(복습 완료)
## 스레드 프로그래밍
### 피터슨 알고리즘
1. 비정상적인 동작의 이유 추적
    1) Lock-Unlock 구간 사이에 CriticalSection을 사용하여 TryCriticalSection를 사용
    2) 두 스레드가 서로 다른 플래그 변수를 가지고 Lock에 진입하였을 때 true로 변경하고, 다른 스레드의 플래그를 확인하여 진입을 확인한다.
        * 이미 앞서 피터슨 알고리즘이 예상대로 작동하지 않았기 때문에, 동시 진입의여부 또한 우리의 예상을 벗어날 수 있다. 
    3) InterlockedExchange를 사용하여 추적
        <pre><code>
        int flagCpy;
        int turnCpy;
        flag[0] = true;
        iTurn = 1;
        while(1)
        {
            // 사본을 만들어 상태 값을 비교
            flagCpy = flag[1];
            turnCpy = iTurn;
            if((flagCpy != true) && (turnCpy != 1))
                break;
        }        
        
        // Lock 진입
        if (1 == InterlockedExchange(&isLock, 1))
            {
                printf("flag: %d / turn: %d\n", flagCpy, turnCpy);
                break;  // 동시에 진입한 경우
            }
        x = 0;
        // Unlock 진입
        </code></pre>
        * 주의해야할 부분: 동시 진입하였을 때 정확한 플래그와 턴 값을 확인하기 위해서 스택 프레임에 사본을 만들어 확인한다.
2. 두 개 이상의 스레드가 있을 때 같이 진입하는 순간을 포착하기위한 방법
    1) 임계 영역에 진입할 때 스레드마다 고유한 값을 특정지어 동시에 진입한 스레드를 판단할 수 있다.
        <pre><code>
        // Lock
        if (0 > InterlockedExchange(&isLock, 1))
            break;  // x번 스레드가 이미 진입함
        isLock = 0;
        // Unlock
        </code></pre>

### 분기 예측
1. 미리 CPU가 cmp, jmp 등을 미리 준비해놓고 예측에 성공하였다면 바로 실행에 옮기는 기법. 실패하면 다시 작업한다.
2. 파이프 라인과 분기 예측으로 인해 비순차적 명령어 처리로 인하여 지금의 상황이 만들어졌다.

### Out of Ordering Execution(OoOE)
1. CPU 내부에서 명령어 처리 순서(=최소 단위 오퍼레이션 단위로)는 재배치 될 수 있다. 하지만 CPU로의 진입과 외부로의 결과 반영의 순서는 지켜진다.
    1) 내부에서 명령어 처리 순서가 재배치되기 때문에 이미 처리된 명령어는 결과 출력만을 대기하는 상태가 된다.
    2) 함수를 뛰어넘어 명령어 재배치를 하는 경우가 발생 할 수 있다. 함수가 처리되지 않은 상태에서 함수보다 더 뒤에 있는 명령을 먼저 실행하는 것이다. 이는 분기 예측과도 연관이 있다.
2. OoOE의 대상
    1) 덧셈, 뺄셈, cmp 같은 경우는 OoOE의 대상이 아니다. Load와 Store 만이 OoOE의 대상이다.
        * 재료만 준비가 되어있다면 먼저하든 나중에하든 상관이 없기 때문이다. 그 재료가 준비되는 순서에 따라 위와 같은 연산은 결과가 달라질 수 있다. 그래서 재배치의 중점은 Load와 Store가 어떤 조건에 의해 재배치가 되는가를 보는 것이다.
        * Load는 연산 전, Store의 경우 연산이 끝난 뒤 시점을 보는 것이다.
    2) Load와 Store에 대한 고민
        * 우리 기준에서는 mov 명령어에서 레지스터->메모리는 Store, 메모리->레지스터는 Load이다.
        * 예를 들어 a = x + y;가 있을 때 x와 y가 Load, a가 Store 되는 시점이 대상이 된다.
        * 연관이 있는 변수, 메모리, 명령어 간에는 재배치되지 못한다. 예를 들면 (1) x = z; (2) y = x;가 있는 경우 (2)가 (1)보다 앞서 재배치 되지 않는다.
3. Load와 Store의 명령어 재배치 조건
    1) <img width=700 src="https://user-images.githubusercontent.com/95362065/167328780-d22d2ea5-f1db-4501-a1ff-1d862ed82fb8.PNG">
    2) Stores can be reordered after loads: x86은 Load가 Store를 앞지를 수 있는 조건 하나만이 있다. 그래서 x86은 Memory Ordering 규칙이 strong하다고 표현한다. 이 외는 Weak라고 한다.
4. 우리의 공부 목적 
    * 실무에서는 OoOE를 논하면서 프로그램을 절대 짜지 않는다. 무조건 동기화 객체를 사용하여 동기화를 구현할 것이다.
    * 우리의 목적은 멀티스레드 환겨엥서 어떤식으로 나타내는지 극단적으로 확인하고 공부하기 위해서 동기화 객체를 최대한 사용하지 않고 프로그램을 하는 것이다. 이러한 고민을 하는 단계는 엔진, 코어 수준, 리드 개발자가 되었을 때 고려해보는 것이다.
5. 예시
    1) 피터슨
        <pre><code>
        flag[0] = true;     // store
        turn = 0;           // store
        while((flag[1] == true) || (turn == 1));    // Load, Load
        * x86 환경이라면 Load가 Store를 앞지를 수 있는 상황이다.
        </code></pre>
    2) 스핀락
        <pre><code>
		while (InterlockedExchange((long*)&g_lock, true))
		{
			YieldProcessor();
		}
        
		g_Data++;           // 임계 영역 작업. Load, Store - (1)
		g_lock = false;     // Store - (2)
        </code></pre>
        * 만약 x86에서 Store가 Load 혹은 Store를 앞지를 수 있다면 임계 영역의 작업이 모두 다 수행되기도 전에 (2)가 먼저 실행될 수 있다. 이 얘기는 즉 Interlocked를 사용하여 Unlock을 해야한다는 얘기와 같다.
6. 참고 사이트: http://cloudrain21.com/out-of-order-processor-pipeline-1

### 메모리 배리어 혹은 메모리 펜스
1. OoOE를 방어하는 동작이다. 
2. 명령어
    1) API 제공
        * _mm_mfence: 완전 펜스, 펜스를 기준으로 이전 명령어들의 작업을 완료하고 펜스 이후 명령어를 수행하겠다. 물론 펜스 이전 명령어들 간의 명령어 재배치는 가능하다. 그러나 펜스 이후의 명령어들이 펜스 이전 명령어들에 침입하여 재배치가 되지 않는 것이다.
        * _mm_lfence: Load 펜스, 해당 펜스 기준 이전 Load를 모두 처리하고 fence 이후 Load 명령을 처리하겠다. 이 얘기는 lfence 이후 load와 lfence 이전 store 간에 재배치는 가능하다는 이야기이다. 사실상 x86에서는 의미가 없는 펜스이다.
        * _mm_sfence: Store 펜스, 해당 펜스 기준 이전 Store를 모두 처리하고 fence 이후 Store 명령을 처리하겠다. 이 또한 _mm_lfence와 같은 특징을 갖는다.
        * 논의점: 그렇다면 _mm_lfence, _mm_sfence를 같이 사용한다면 _mm_mfence의 효과가 나는 것이냐? => 아니다! _mm_lfence, _mm_sfence는 그저 펜스 이전 store 혹은 load의 작업을 마치는 것을 보장해주는 것이지, mfence 처럼 펜스 이후의 store나 load가 펜스 이전 명령어에 침투하여 재배치 되는 것을 막아주지는 못하기 때문이다.
    2) C 런타임 제공
        * __faststorefence: 하드웨어 베리어 펜스이다. inline 처리가 되어 lock or dword ptr [rsp], 0로 변환되는데 이는 아무런 의미없는 Interlocked 동작이다. Interlocked을 사용하는 이유는 모든 Interlocked은 명령어 재배치를 막기 때문이다. 막는다. _mm_mfence 보다 빠르다.
        * _ReadWriteBarrier: 컴파일러 최적화를 제한하는 컴파일러 베리어이다. 컴파일 단계에서 Out of Ordering을 막는 동작을 한다. __ReadWriteBarrier를 기준으로 컴파일 최적화로 인한 명령어 순서가 바뀌는 것을 막는 역할을 한다.
        * __MemoryBarrier: __fastStoreBarrier로 define 되어 있다.
    3) C++ 표준(atomic_thread_fence, x86에서는 이 개념이 없다.)
        * Acquire 시멘틱: 밑에 있는 Load나 Store를 위로 올리지 않겠다. Acquire의 동작의 목적은 아래 명령어를 수행하기 위해 어떤 재료를 준비해야하는데 목적이 있기 때문이다.
        * Release 시멘틱: 위에 있는 Load나 Store를 아래로 내리지 않겠다. 할 거 다 하고 모두 내려놓겠다의 목적을 가짐
        * 현재 x86에서는 Acquire와 Release 개념은 존재하지 않는다. 앞으로의 할 일에 대해서 펜스를 치는 행위이다.

### Interlocked
1. Interlocked은 해당 명령어가 그 자리에서 동작을 완료해야 하기 때문에 mfence와 같이 Interlocked 이전 명령어들의 처리 완료를 보장한다. Interlocked은 결론적으로 메모리 순서를 지켜주고 기다리는 상황을 만들기 때문에 메모리 배리어 효과를 낸다.
    * 하지만 Interlocked는 본래 펜스 역할이 아니다! 명심

### 기타
1. Out Of Ordering 이슈 (AMD)
    1) 멜트 다운: OoOE로 인해 유저 단계에서 커널 메모리에 전급할 수 있는 방식이 노출이 되었다.
    2) 스펙터: 분기 예측에 의해서 코드가 잘못 전달되는 상황을 만들 수 있는 문제
2. OoOE를 하는 이유
    1) 파이프라인과 같이 사용하여 CPU의 효율 극대화를 위하여(병렬 처리)

## 기타 키워드
### 과제
1. 피터슨 알고리즘에 펜스를 쳐서 정상 동작 구현해보기
2. x86 메모리 오더링에 규칙에 맞춰서 fence를 안쳐도 해결되는 상황을 언어 수준에서 수정해보고 테스트 해본다. 이때 왜 정상적인 동작이 되지 않는지에 대하여 고민해보기
