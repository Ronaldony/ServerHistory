## 메모리
### 예외처리
1. 메모리 할당 실패 시 프로그램을 다운시키는게 "정상적" 동작이다.
2. 유저를 찾는 과정이 있는데(유저는 어떠한 리스트에 무조건 존재한다고 가정), 찾지 못하였다면 결함으로 인식하여 프로그램을 다운시켜야 한다. (더이상의 코드를 진행시키면 안됨)
	* 프로그램 종료: nullptr 주소에 쓰기 접근

### 캐시 메모리
1. Core마다 각각 L1, L2가 구성되고 L3(스마트 캐시)는 공유한다.
2. 캐시 히트: Core가 캐시에 데이터를 요청하였을때 데이터가 존재하는 상황 <-> 캐시 미스: 캐시 히트의 반대
	1) Core는 캐시 L1->L2->L3->RAM 순으로 데이터를 찾는다. RAM에도 없다면 MMU가 Page Fault를 발생시켜 해당 메모리를 Page In(해당 프로세스는 Block되어 Ready 상태로 진입)
3. 캐시 메모리의 특성
	1) 캐시 메모리는 메인 메모리에서 캐시 라인 단위(64byte)로 가져온다.
	2) 캐시 메모리는 코드 캐시와 데이터 캐시로 1/2씩 공간이 나누어진다. 코드영역 데이터는 코드 캐시로 데이터(Heap, 데이터, Stack 영역)는 데이터 캐시에 저장된다.
	3) Core들은 캐시 라인 내 데이터의 변화를 다른 Core들에게 알려 같은 데이터를 가진 캐시 라인을 무효화(삭제)시킨다.(MESI 프로토콜)
		* 캐시 라인들은 캐시 미스가 날 경우, 같은 레벨의 캐시->다음 레벨 캐시 순으로 검색하여 데이터를 가져온다.
4. 캐시 메모리 쓰기 정책
	1) write back(데이터 캐시): 변경된 데이터를 캐시에만 적용
		* 메모리 적용시기는 해당 캐시 데이터가 캐시 라인에서 지워질 때 이다.
	2) write through(코드 캐시): 변경된 데이터를 메모리까지 적용
5. 캐시 메모리 저장 방법
	1) Inclusive: 상위 계층 캐시에 포함된 데이터가 하위 계층 캐시에 반드시 포함되는 구조(인텔 CPU)
	2) Exclusive: 상위 계층과 하위 계층 캐시에 저장된 데이터가 서로 배타적인 구조
	3) 참조: https://velog.io/@kjh3865/캐시-메모리-정리

### 캐시히트율
1. 캐시 히트를 높이는 방법 1 (쓰기나 읽기 어느 하나의 단일 동작 시)
	1) 시간적 근접성: 연속적인 동작에 같은 변수를 사용
	2) 지역적 근접성: 연속된 주소 값의 메모리를 사용
	<pre><code>
	strcut alignas (64) stData
	{
		// Data 정의
	};
	* 구현: struct alignas(캐시 라인 크기)로 정의하여 최대한 연속적인 주소를 가진 데이터를 사용
	</code></pre>
2. 캐시 히트를 높이는 방법 2 (읽기와 쓰기를 동시에 동작하는 경우)
	1) 읽기 변수와 쓰기 변수를 의도적으로 다른 캐시 라인에 적재하여, 읽기 변수의 캐시 라인 무효화를 막는다.
	2) 구현
	<pre><code>
	alignas (64) int read;
	alignas (64) int write;	
	</code></pre>
3. 지역 변수와 전역 변수에 접근하는 속도에는 차이가 없다.
	* 단지 캐시 히트 여부에 따른 속도 차이이다. (지역과 전역을 섞어 사용하면 캐시 미스 확률이 높아진다.)

### malloc 할당 실패는 가상메모리 상에서의 공간이 부족한 경우이다. (OS입장에서 물리 메모리는 무한하다고 보기 때문이다.)
