# 2022/05/25 수업내용
# IO
## 비동기 IO
### 파일 비동기 IO의 문제점
1. 한 파일을 대상으로 비동기 Output을 중첩하면 데이터가 덮어써져 버린다. OVERLAPPED 구조체의 파일 위치 정보를 건드려 
2. 파일 IO의 Overlapped IO 조건은 캐시되지 않은 것에 대해서만 작동된다. OS는 파일에 대한 IO를 캐시를 저장해놓는다. 이 작업은 C 런타임의 버퍼링이 아니라 OS에서 파일 시스템 내부에서 버퍼링하는 작업인 것이다.
    * 캐시가 되지 않은 대상으로만 파일 IO가 Overlapped 가 작동된다. Disk에 

### Overlapped
1. Overlapped IO를 사용하는 경우 OVERLAPPED 구조체에 명시된 포지션을 기준으로 파일 IO가 이루어진다.
2. Overlapped IO가 작동되려면 디바이스에 걸려야 한다. 즉, Overlapped IO의 작동 조건은 데이터를 어느 버퍼에 넣고 빠지는 행위가 아니라 디바이스에 버퍼의 주소 정보를 IO 걸어야 한다.
    * Overlapped IO가 작동되는 조건을 만족시켜야 Overlapped IO가 작동되는 것이다. Block 걸리는 조건과 매칭시키면 이해하기 쉽다.
    * IO_PENDDING 이 일어났다면 Overlapped IO가 이루어진 것이다.
3. 옛날 개발자들은 처음 Overlapped가 나왔을 때 이러한 고민들을 했다
    1) 파일 Overlapped가 작동될 때 정말로 동시에 이루어지는가? 이렇게 되면 어떠한 문제가 발생할 것인가?
    2) 소켓 작업 시 어차피 백그라운드에서 Overlapped IO를 진행할 것이기 때문에 WSASend를 마구잡이로 호출하면 성능이 더 좋아지지 않겠는가?
        * 이 상황에 대한 걱정 거리: 파일 IO처럼 네트워크 IO가 중첩으로 이루어질 때, 100->200->150 크기만큼 요청 했을 때 반환된 값은 70->100->... 이렇게 되면 어떻게 결과를 판단해야 하는 것인가? 실제로 일반 send에서도 이러한 상황이 벌어지는데 => 그래서 하나의 소켓에 대하여 중첩으로 IO를 걸지말자라는 것이다. 이전에 했던 Send가 완료되어야만 다음 Send 작업을 하자! 라는 의미이다.

### 소켓 비동기 IO
1. 상황
    1) 한 소켓에 대하여 WSASend를 3번 호출하는데 매번 다른 버퍼를 입력한다. 차례로 100->200->150 크기로 전송 요청했을 때 작업 완료에 대한 순서와 크기가 지켜지지 않는가?
        * 결론적으로 순서와 크기에 대한 반환 값은 모두 요청과 정확히 일치한다. 아래 Overlapped의 동작 조건을 살펴보자. 소켓 버퍼에 공간이 없어 디바이스에 IO를 걸고 빠지는 상태가 된다.
        * GetOverlappedResult 호출 후에 수신하거나 송신한 크기보다 작은 크기 반환 값에 대비한 코드가 있다. 앞서 말했던 결론으로 인해 이러한 코드는 절대! 불필요한 코드인 것이다.
    2) 1번과 관련하여 그러나 우리는 여전히 Send와 Recv 동작을 1번씩만 한다. 그 이유는 다음과 같다
        * 1: Overlapped 작동 성능이 좋지 않기 때문이다. 
        * 2: Overlapped 구조체를 어떻게 관리할 것이냐의 문제도 있다. => 세션 별로 Overlapped 포인터를 두어 동적 할당하여 관리하자는 아이디어가 있다. 이 방법은 동적 할당에 대한 오버헤드가 생긴다.
        * 3: 실제로 Overlapped가 작동되기 위해서 윈도우 시스템은 무엇을 하는가이다. Block 소켓에서 recv와 send가 block 걸리는 상황에서는 유저 메모리를 디바이스가 직접 접근하는 것이다. 그래야지 디바이스가 작동되는 것이기 때문이다.
        * Page Lock -> 디바이스에 Non-Paged에 대한 Overlapped 작업 요청 후에야 IO pending이 반환이 된다. 이 상황이 IO 작업보다 과연 짧은가? 중첩 IO 시 성능이 더 좋아지는가? -> 이것에 대한 판단은 직접 테스트해보고 결론을 내릴 것
    3) 만약 Overlapped IO를 사용한다면 우려 사항이 2가지가 있다. Non-Page Pool에 대한 크기 걱정과 Page Lock이다.
2. 소켓에서의 Overlapped 작동 조건
    1) 송신: 소켓 버퍼에 공간이 없는 경우, 따라서 
3. Zero copy: 중간 버퍼의 Copy 행위를 없애서 성능을 높여보자. 이것은 우리 입장에서 Overlapped 이다.
    1) Zero copy의 대상 버퍼는 Page out 되지 않아야 한다. 따라서 Page Lock이 걸린다. 이후 해당 Page에 대한 
    2) Request IO pakage에 대한 작업을 관리하는 주체는 스레드이다. 그 이유는 요청하는 주체가 일단 스레드IO라는 작업은  
        * 동기 IO라면 Request IO paket은 하나가 된다. 그러나 비동기 IO라면 다수의 Request IO paket이 생겨 관리가 필요하다. Request IO paket는 Non-Paged Pool에 저장된다.
        * Request IO paket: IO의 요청 수

### Page Lock
1. Page Lock는 물리 메모리의 x%의 크기로 제한이 된다. 

### 소켓 에러
1. WSAENOBUFS
    1) Page Lock에 실패하거나 Non-Page Pool에 대한 확보가 실패되면 반환되는 에러값
    2) 이 에러가 나오면 서버를 종료시키는 것보단 해당 유저의 연결을 끊는 것이 낫다.
    3) 대처 방안
        * 첫 번째: Non-Paged pool 크기를 확인한 후 실제 Scale up
        * 두 번째: 
        * 최후의 방법: 동접자 줄이기
2. 에러 값을 찍는 것은 일반적인 에러와 일반적이지 않은 에러를 구분하는 것에 목적이 있다.
    1) 따라서 일반적인 에러들을 

### IOCP
1. 작업 완료의 기준: 연결이 끊겼거나 진짜 작업이 완료되었거나 이다.
2. 다른 스레드가 아닌 내 스레드가 APC 큐에서 디큐잉해서 완료 루틴을 호출한다.
    1) alertable wait: APC 큐에 있는 함수 호출을 기다리는 상태 
3. APC 큐의 단점
    1) 스레드가 자기만의 APC큐를 가지기 때문에 IO 완료 통지가 해당 스레드에만 전달된다. 다른 스레드에 분산이 안 된다.
4. 완료 루틴을 호출하는 도중에 APC 큐에 쌓일 수 가 있다. 이때 Alertable wait 상태라면 APC 큐에 있는 함수를 모두 호출하고 리턴이 된다.
5. 우리는 APC 큐 방식을 사용하지 않을거지만 활용할 것이다.
    1) 우리는 완료 통지 목적으로 APC를 사용하는게 아니라 의도적으로 UserAPCQueue 함수를 호출하여 사용할 것이다.
