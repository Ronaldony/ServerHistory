## 캐시 메모리
  1. Tool: CPU-Z

  2. i3, i5, i7 등 64bit에서는 캐시 메모리의 크기가 동일하다. 단, Core 수에 따라 총 캐시 메모리 크기는 달라질 수 있다.

  3. 캐시 메모리 크기 및 저장되는 캐시 라인수 구하기

    1) 작업관리자->성능 메뉴에서 캐시 정보(L1..3)에서 Core 개수(실제 Core, 논리 프로세서 x)와 2(데이터, 코드영역)을 나누면 단일 캐시 메모리 크기(데이터 영역)가 계산된다.
      => 예시: L1 캐시 정보가 128KB인 경우 - 128/2/2 = 32KB. 이렇게 구해진 32KB에서 캐시라인 크기(64)로 나누면 캐시 메모리 데이터 영역에 들어갈 수 있는 캐시 라인의 개수가 계산된다.(512)

  4. Core와 Cache 메모리 동작

    1) 메모리에서 가져온 주소 값을 캐시 라인 크기에 맞게 주소 정렬 (64로 마스킹 = 캐시 라인 Offset을 정리). 주소값이 32bit라면 LSB부터 6bit(offeset), 9bit(Index), 17bit(Tag)로 영역을 나눈다.
      => 1-way: 캐시 메모리에 적재하려는 두 데이터의 주소 Index가 같으면 같은 캐시 메모리 안에서 같은 지점에 들어간다(=데이터를 덮어씀). 따라서 Index가 겹치지않게 프로그램하는 것이 캐시 히트율을 높일 수 있다.
      => n-way: 1-way를 개선하기 위해  n-way(하나의 인덱스에 n개의 Tag에 대한 메모리를 저장)가 도입된다. n-way를 도입하면 Index의 크기가 /n만큼 줄어들고 Tag가 n만큼 늘어난다. 예를 들어 8-way라면 캐시 메모리에 캐시 라인 개수가 512개 일 때, Index 최대 크기는 512/8 = 64가 된다(6bit, 0 ~63)
    2) 캐시 라인 검색: 같은 Index 참조 -> Tag 참조 -> Offset 참조순으로 주소 값에 맞는 데이터 캐시 히트
      => Index bit자리가 증가한다 -> Index의 주소 대역이 좁아져 비슷한 대역 안에서 캐시 히트율이 높아진다.(검사 필요)
      => Index bit자리가 감소한다 -> Tag 자리가 넓어지고 프로그램들의 메모리 사용량이 커져 Index의 대역이 넓어짐.

  5. TLB(주소 변환 버퍼)

    1) 캐시메모리(L1, L2, L3 모두)에 붙어있어 물리-가상 메모리 주소를 빠르게 맵핑(변환)하는 버퍼
    2) 캐시는 물리주소 or 가상주소 or 물리+가상주소의 방식 3가지로 주소 검새 방법이 있다. 각 캐시 레벨에 따라 검색 방법이 다르다.(way 또한)
      => 물리주소(Direct Mapping): 단점 - 가상주소로 변환을 하여야 함. (프로그래머 입장에서는 가상주소가 베이스이기 때문에) RAM에서 Page In, Page out 할 때마다 캐시 메모리를 비워야 한다. (RAM의 페이지주소는 계속해서 바뀌기 때문이다.)
      => 가상주소(Associate Mapping): 단점 - 프로세스의 컨택스트 스위칭 시 Core들이 캐시 무효화가 많이 일어남. 어떤 프로세스의 어떤 주소다라는 정보를 가지고 있어야 한다.
      => 물리 + 가상주소(VIPT): 캐시 라인 Index+offset의 크기를 가상 주소의 Page 단위(4KB)로 물리 주소에 맵핑하는 방법이다. TLB가 물리-가상 주소를 맵핑시킬 때 주소의 Index+offset 영역에 대한 추가적인 변환없이 Tag 값으로만 페이지 테이블에 접근하여 페이지 정보를 가져온다. Page단위와 Index+offset의 크기와 다르다면 물리+가상이 아닌 물리 혹은 가상 주소 맵핑일 확률이 높다.

  6. 캐시 히트율 시뮬레이션

    1) 실제로 캐시 메모리 모델을 시뮬레이션으로 구현해서 문제점을 파악하면 베스트
